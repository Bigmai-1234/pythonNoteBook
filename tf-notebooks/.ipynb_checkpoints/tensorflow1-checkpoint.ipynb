{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#构建数据\n",
    "x_data = np.float32(np.random.rand(2,100))\n",
    "y_data = np.dot([0.100,0.200],x_data) + 0.300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_5:0' shape=(1, 2) dtype=float32_ref>\n",
      "0 [[0.64482355 0.6003032 ]] [-0.3647016]\n",
      "20 [[0.32570857 0.38515016]] [0.09386829]\n",
      "40 [[0.18498668 0.27234226]] [0.22108695]\n",
      "60 [[0.13226072 0.22795844]] [0.26979905]\n",
      "80 [[0.11229541 0.21074915]] [0.28844348]\n",
      "100 [[0.10469537 0.20412235]] [0.29557818]\n",
      "120 [[0.10179479 0.20157903]] [0.29830816]\n",
      "140 [[0.10068637 0.20060447]] [0.29935268]\n",
      "160 [[0.10026257 0.20023134]] [0.29975232]\n",
      "180 [[0.10010044 0.20008855]] [0.29990524]\n",
      "200 [[0.1000384  0.20003387]] [0.29996374]\n"
     ]
    }
   ],
   "source": [
    "#构建损失函数\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "y = tf.matmul(W, x_data) + b\n",
    "\n",
    "#损失计算\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "#参数训练方法\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "#初始化参数\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#迭代训练\n",
    "for step in range(0, 201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print (step, sess.run(W), sess.run(b))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "0.9132\n"
     ]
    }
   ],
   "source": [
    "###手写体数据导入\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/', one_hot=True)\n",
    "\n",
    "#参数设置\n",
    "x = tf.placeholder(\"float\",[None,784])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "\n",
    "#损失函数\n",
    "y_ = tf.placeholder(\"float\", [None,10])\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "#变量初始化\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "#迭代训练\n",
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    \n",
    "    \n",
    "#评估模型   \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.14\n",
      "step 100, training accuracy 0.82\n",
      "step 200, training accuracy 0.92\n",
      "step 300, training accuracy 0.92\n",
      "step 400, training accuracy 0.88\n",
      "step 500, training accuracy 0.98\n",
      "step 600, training accuracy 0.94\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.94\n",
      "step 900, training accuracy 0.96\n",
      "step 1000, training accuracy 0.96\n",
      "step 1100, training accuracy 0.96\n",
      "step 1200, training accuracy 0.96\n",
      "step 1300, training accuracy 0.98\n",
      "step 1400, training accuracy 0.96\n",
      "step 1500, training accuracy 0.98\n",
      "step 1600, training accuracy 1\n",
      "step 1700, training accuracy 0.98\n",
      "step 1800, training accuracy 0.96\n",
      "step 1900, training accuracy 0.96\n",
      "test accuracy 0.9749\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tf.truncated_normal\n",
    "这个函数产生正太分布，均值和标准差自己设定。这是一个截断的产生正太分布的函数，\n",
    "就是说产生正太分布的值如果与均值的差值大于两倍的标准差，那就重新生成。\n",
    "\n",
    "\"\"\"\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\"\"\"\n",
    "tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)\n",
    "\n",
    "第一个参数input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，\n",
    "具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，注意这是一个4维的Tensor，要求类型为float32和float64其中之一\n",
    "\n",
    "第二个参数filter：相当于CNN中的卷积核，它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，\n",
    "具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同，\n",
    "有一个地方需要注意，第三维in_channels，就是参数input的第四维\n",
    "第三个参数strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4\n",
    "第四个参数padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，这个值决定了不同的卷积方式\n",
    "第五个参数：use_cudnn_on_gpu:bool类型，是否使用cudnn加速，默认为true\n",
    "结果返回一个Tensor，这个输出，就是我们常说的feature map，shape仍然是[batch, height, width, channels]这种形式。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for i in range(2000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print (\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print (\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
